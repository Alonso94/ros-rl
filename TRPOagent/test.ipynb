{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_crumb\n",
    "from agent.agent_TRPO import TRPOAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "if os.environ.get(\"DISPLAY\") is str and len(os.environ.get(\"DISPLAY\"))!=0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"crumb-synthetic-v0\")\n",
    "agent = TRPOAgent(env)\n",
    "#agent.net.Loadmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** Iteration 1 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2043\n",
      "Average sum of rewards per episode:       -50.8613641703\n",
      "Std of rewards per episode:               56.9045915139\n",
      "Entropy:                                  -60872.218777948474\n",
      "KL between old and new distribution:      0.00994523350393292\n",
      "Surrogate loss:                           254222.46390111206\n",
      "\n",
      "********** Iteration 2 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2042\n",
      "Average sum of rewards per episode:       -48.3803109696\n",
      "Std of rewards per episode:               55.6604659154\n",
      "Entropy:                                  -60709.83942483559\n",
      "KL between old and new distribution:      0.009960627742706635\n",
      "Surrogate loss:                           243922.2528730768\n",
      "\n",
      "********** Iteration 3 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2046\n",
      "Average sum of rewards per episode:       -47.3466212121\n",
      "Std of rewards per episode:               54.860571821\n",
      "Entropy:                                  -60448.13697359886\n",
      "KL between old and new distribution:      0.009897398750875596\n",
      "Surrogate loss:                           235854.26593136005\n",
      "\n",
      "********** Iteration 4 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2043\n",
      "Average sum of rewards per episode:       -43.9199021047\n",
      "Std of rewards per episode:               53.3000826068\n",
      "Entropy:                                  -60266.876549410124\n",
      "KL between old and new distribution:      0.009916587877968886\n",
      "Surrogate loss:                           223907.3202835685\n",
      "\n",
      "********** Iteration 5 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2042\n",
      "Average sum of rewards per episode:       -41.2962252693\n",
      "Std of rewards per episode:               47.4389451828\n",
      "Entropy:                                  -60124.12123874281\n",
      "KL between old and new distribution:      0.009912442120541187\n",
      "Surrogate loss:                           211416.90479228558\n",
      "\n",
      "********** Iteration 6 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2041\n",
      "Average sum of rewards per episode:       -40.9305007349\n",
      "Std of rewards per episode:               49.4414497296\n",
      "Entropy:                                  -59836.5807342338\n",
      "KL between old and new distribution:      0.009887328624188453\n",
      "Surrogate loss:                           208445.28235853178\n",
      "\n",
      "********** Iteration 7 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2039\n",
      "Average sum of rewards per episode:       -37.7780593428\n",
      "Std of rewards per episode:               46.8582351876\n",
      "Entropy:                                  -59660.46790956811\n",
      "KL between old and new distribution:      0.009874383105045287\n",
      "Surrogate loss:                           196066.65041860516\n",
      "\n",
      "********** Iteration 8 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2034\n",
      "Average sum of rewards per episode:       -35.7133647984\n",
      "Std of rewards per episode:               40.1684487344\n",
      "Entropy:                                  -59532.47866010024\n",
      "KL between old and new distribution:      0.009957183944743056\n",
      "Surrogate loss:                           179123.41862834353\n",
      "\n",
      "********** Iteration 9 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2030\n",
      "Average sum of rewards per episode:       -37.8593807882\n",
      "Std of rewards per episode:               42.1402552936\n",
      "Entropy:                                  -59322.50438507611\n",
      "KL between old and new distribution:      0.009850734928257042\n",
      "Surrogate loss:                           191310.26333477852\n",
      "\n",
      "********** Iteration 10 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2026\n",
      "Average sum of rewards per episode:       -36.9249772952\n",
      "Std of rewards per episode:               42.7646054\n",
      "Entropy:                                  -59069.263961386954\n",
      "KL between old and new distribution:      0.00991353789245172\n",
      "Surrogate loss:                           187740.55977299993\n",
      "\n",
      "********** Iteration 11 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2023\n",
      "Average sum of rewards per episode:       -34.4439881364\n",
      "Std of rewards per episode:               39.3493616236\n",
      "Entropy:                                  -58965.43009738924\n",
      "KL between old and new distribution:      0.009984170269390722\n",
      "Surrogate loss:                           172596.90032546947\n",
      "\n",
      "********** Iteration 12 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2023\n",
      "Average sum of rewards per episode:       -32.6577553139\n",
      "Std of rewards per episode:               37.2660229248\n",
      "Entropy:                                  -58699.742950725515\n",
      "KL between old and new distribution:      0.009949037579905746\n",
      "Surrogate loss:                           161645.8778600847\n",
      "\n",
      "********** Iteration 13 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2016\n",
      "Average sum of rewards per episode:       -31.4570704365\n",
      "Std of rewards per episode:               35.5778326469\n",
      "Entropy:                                  -58496.10644131404\n",
      "KL between old and new distribution:      0.009851692960468788\n",
      "Surrogate loss:                           158662.8732536492\n",
      "\n",
      "********** Iteration 14 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2033\n",
      "Average sum of rewards per episode:       -31.0560949336\n",
      "Std of rewards per episode:               35.8187346614\n",
      "Entropy:                                  -58364.486685927994\n",
      "KL between old and new distribution:      0.009948721337953433\n",
      "Surrogate loss:                           155382.76679216465\n",
      "\n",
      "********** Iteration 15 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2018\n",
      "Average sum of rewards per episode:       -29.2759340932\n",
      "Std of rewards per episode:               32.3958741177\n",
      "Entropy:                                  -58144.97170607598\n",
      "KL between old and new distribution:      0.00992276747411712\n",
      "Surrogate loss:                           149944.1982873458\n",
      "\n",
      "********** Iteration 16 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2020\n",
      "Average sum of rewards per episode:       -29.7091524752\n",
      "Std of rewards per episode:               34.3968004593\n",
      "Entropy:                                  -57878.84282481688\n",
      "KL between old and new distribution:      0.009845993989240192\n",
      "Surrogate loss:                           153815.98392832652\n",
      "\n",
      "********** Iteration 17 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2013\n",
      "Average sum of rewards per episode:       -29.0544351714\n",
      "Std of rewards per episode:               31.165271578\n",
      "Entropy:                                  -57694.08238982725\n",
      "KL between old and new distribution:      0.00987799090673621\n",
      "Surrogate loss:                           145831.42037969516\n",
      "\n",
      "********** Iteration 18 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2015\n",
      "Average sum of rewards per episode:       -27.769474938\n",
      "Std of rewards per episode:               29.6205721026\n",
      "Entropy:                                  -57574.77746987902\n",
      "KL between old and new distribution:      0.009921343524442452\n",
      "Surrogate loss:                           141415.92010043105\n",
      "\n",
      "********** Iteration 19 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2011\n",
      "Average sum of rewards per episode:       -27.6200447539\n",
      "Std of rewards per episode:               28.8297289757\n",
      "Entropy:                                  -57380.23811301017\n",
      "KL between old and new distribution:      0.009890390530969411\n",
      "Surrogate loss:                           139518.949101363\n",
      "\n",
      "********** Iteration 20 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2012\n",
      "Average sum of rewards per episode:       -26.3939816103\n",
      "Std of rewards per episode:               29.3143790957\n",
      "Entropy:                                  -57157.28890593649\n",
      "KL between old and new distribution:      0.009958467091924396\n",
      "Surrogate loss:                           136636.2728492332\n",
      "\n",
      "********** Iteration 21 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2011\n",
      "Average sum of rewards per episode:       -26.630215813\n",
      "Std of rewards per episode:               26.7806621457\n",
      "Entropy:                                  -57023.78948189081\n",
      "KL between old and new distribution:      0.009954962843727766\n",
      "Surrogate loss:                           137901.63889526136\n",
      "\n",
      "********** Iteration 22 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2007\n",
      "Average sum of rewards per episode:       -24.5130901844\n",
      "Std of rewards per episode:               25.6543898738\n",
      "Entropy:                                  -56717.3573558682\n",
      "KL between old and new distribution:      0.009895241198635054\n",
      "Surrogate loss:                           125985.73550402894\n",
      "\n",
      "********** Iteration 23 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2012\n",
      "Average sum of rewards per episode:       -24.2337117296\n",
      "Std of rewards per episode:               23.0985147638\n",
      "Entropy:                                  -56576.1350066138\n",
      "KL between old and new distribution:      0.009935015756541807\n",
      "Surrogate loss:                           124602.53042155883\n",
      "\n",
      "********** Iteration 24 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -23.2449375936\n",
      "Std of rewards per episode:               25.0099957492\n",
      "Entropy:                                  -56378.85557527197\n",
      "KL between old and new distribution:      0.009917860524057645\n",
      "Surrogate loss:                           116709.02956563592\n",
      "\n",
      "********** Iteration 25 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2011\n",
      "Average sum of rewards per episode:       -23.7041049229\n",
      "Std of rewards per episode:               22.9376001277\n",
      "Entropy:                                  -56167.53408311179\n",
      "KL between old and new distribution:      0.009934825124239821\n",
      "Surrogate loss:                           119816.28066637181\n",
      "\n",
      "********** Iteration 26 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2008\n",
      "Average sum of rewards per episode:       -22.8655697211\n",
      "Std of rewards per episode:               25.429658945\n",
      "Entropy:                                  -55928.97250361833\n",
      "KL between old and new distribution:      0.009898256885669152\n",
      "Surrogate loss:                           118632.38086114127\n",
      "\n",
      "********** Iteration 27 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -22.8223265204\n",
      "Std of rewards per episode:               23.5440364664\n",
      "Entropy:                                  -55765.63811279399\n",
      "KL between old and new distribution:      0.009986444191784018\n",
      "Surrogate loss:                           116395.86603965808\n",
      "\n",
      "********** Iteration 28 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -23.3538003992\n",
      "Std of rewards per episode:               21.4364324273\n",
      "Entropy:                                  -55653.08532485853\n",
      "KL between old and new distribution:      0.009865360147248854\n",
      "Surrogate loss:                           119184.56782214931\n",
      "\n",
      "********** Iteration 29 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -22.26939332\n",
      "Std of rewards per episode:               22.8047544812\n",
      "Entropy:                                  -55382.51809498149\n",
      "KL between old and new distribution:      0.009988595116337342\n",
      "Surrogate loss:                           113141.5160897161\n",
      "\n",
      "********** Iteration 30 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -22.2700299252\n",
      "Std of rewards per episode:               22.9209270978\n",
      "Entropy:                                  -55200.70610225599\n",
      "KL between old and new distribution:      0.009923415655487114\n",
      "Surrogate loss:                           116208.64625253993\n",
      "\n",
      "********** Iteration 31 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -22.5543652695\n",
      "Std of rewards per episode:               22.0371515446\n",
      "Entropy:                                  -54939.77608952817\n",
      "KL between old and new distribution:      0.009984210804715716\n",
      "Surrogate loss:                           112905.27254073725\n",
      "\n",
      "********** Iteration 32 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -22.2838783649\n",
      "Std of rewards per episode:               23.2837957555\n",
      "Entropy:                                  -54824.624334853674\n",
      "KL between old and new distribution:      0.009985655420784773\n",
      "Surrogate loss:                           113035.79785921752\n",
      "\n",
      "********** Iteration 33 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -21.4328528678\n",
      "Std of rewards per episode:               20.1554171369\n",
      "Entropy:                                  -54637.82342876117\n",
      "KL between old and new distribution:      0.009905737788481007\n",
      "Surrogate loss:                           110491.48580121073\n",
      "\n",
      "********** Iteration 34 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -21.4389006986\n",
      "Std of rewards per episode:               22.4268839631\n",
      "Entropy:                                  -54397.18344354966\n",
      "KL between old and new distribution:      0.009947141030602147\n",
      "Surrogate loss:                           108748.19493736181\n",
      "\n",
      "********** Iteration 35 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -20.1424515968\n",
      "Std of rewards per episode:               21.2147783818\n",
      "Entropy:                                  -54198.47532511998\n",
      "KL between old and new distribution:      0.009906070025180479\n",
      "Surrogate loss:                           104186.00616179132\n",
      "\n",
      "********** Iteration 36 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -20.9941487768\n",
      "Std of rewards per episode:               20.3658943458\n",
      "Entropy:                                  -54008.0059288043\n",
      "KL between old and new distribution:      0.009934187698168949\n",
      "Surrogate loss:                           107851.30728635569\n",
      "\n",
      "********** Iteration 37 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2001\n",
      "Average sum of rewards per episode:       -19.630894053\n",
      "Std of rewards per episode:               21.4947320769\n",
      "Entropy:                                  -53814.06232080066\n",
      "KL between old and new distribution:      0.009956470258167321\n",
      "Surrogate loss:                           101457.11763387393\n",
      "\n",
      "********** Iteration 38 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -20.7259945055\n",
      "Std of rewards per episode:               21.5428495151\n",
      "Entropy:                                  -53549.804865412\n",
      "KL between old and new distribution:      0.009834807653140609\n",
      "Surrogate loss:                           103885.61399409572\n",
      "\n",
      "********** Iteration 39 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -20.4240913174\n",
      "Std of rewards per episode:               20.7826815774\n",
      "Entropy:                                  -53338.49931892544\n",
      "KL between old and new distribution:      0.009856787426435925\n",
      "Surrogate loss:                           104100.98146049502\n",
      "\n",
      "********** Iteration 40 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -19.8169740648\n",
      "Std of rewards per episode:               21.1023207487\n",
      "Entropy:                                  -53088.74509476316\n",
      "KL between old and new distribution:      0.009978451278023541\n",
      "Surrogate loss:                           102413.66158214437\n",
      "\n",
      "********** Iteration 41 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -19.116165005\n",
      "Std of rewards per episode:               20.305602164\n",
      "Entropy:                                  -52931.44342785218\n",
      "KL between old and new distribution:      0.009996138993935833\n",
      "Surrogate loss:                           98912.44173919369\n",
      "\n",
      "********** Iteration 42 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -19.3327024463\n",
      "Std of rewards per episode:               20.2149017651\n",
      "Entropy:                                  -52713.90204693265\n",
      "KL between old and new distribution:      0.009998727527848209\n",
      "Surrogate loss:                           99182.2200215197\n",
      "\n",
      "********** Iteration 43 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -19.6380104843\n",
      "Std of rewards per episode:               22.1677552444\n",
      "Entropy:                                  -52557.90078787407\n",
      "KL between old and new distribution:      0.00992658319543644\n",
      "Surrogate loss:                           99184.6269270361\n",
      "\n",
      "********** Iteration 44 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -18.116046953\n",
      "Std of rewards per episode:               20.1040031037\n",
      "Entropy:                                  -52306.61431870306\n",
      "KL between old and new distribution:      0.009909618290610598\n",
      "Surrogate loss:                           93986.58187071011\n",
      "\n",
      "********** Iteration 45 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -18.2024076846\n",
      "Std of rewards per episode:               18.4260044391\n",
      "Entropy:                                  -52094.24986512271\n",
      "KL between old and new distribution:      0.009969886449088354\n",
      "Surrogate loss:                           92471.90249129657\n",
      "\n",
      "********** Iteration 46 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -17.5985072391\n",
      "Std of rewards per episode:               17.5721692436\n",
      "Entropy:                                  -51923.01927561299\n",
      "KL between old and new distribution:      0.00991947276644568\n",
      "Surrogate loss:                           91920.85204461354\n",
      "\n",
      "********** Iteration 47 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -17.6549795205\n",
      "Std of rewards per episode:               18.2783643649\n",
      "Entropy:                                  -51704.183836083794\n",
      "KL between old and new distribution:      0.009997854048156805\n",
      "Surrogate loss:                           91107.90700573142\n",
      "\n",
      "********** Iteration 48 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -16.8105573852\n",
      "Std of rewards per episode:               20.6008447835\n",
      "Entropy:                                  -51451.904001250936\n",
      "KL between old and new distribution:      0.009967144496689876\n",
      "Surrogate loss:                           88079.08366175235\n",
      "\n",
      "********** Iteration 49 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -17.4945463609\n",
      "Std of rewards per episode:               21.9047303176\n",
      "Entropy:                                  -51301.49212655671\n",
      "KL between old and new distribution:      0.009940340768933223\n",
      "Surrogate loss:                           89762.16676982662\n",
      "\n",
      "********** Iteration 50 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -17.4590284289\n",
      "Std of rewards per episode:               18.570287915\n",
      "Entropy:                                  -51061.57256268964\n",
      "KL between old and new distribution:      0.009927588631261614\n",
      "Surrogate loss:                           88165.52829032931\n",
      "\n",
      "********** Iteration 51 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -16.4784396208\n",
      "Std of rewards per episode:               19.0902768961\n",
      "Entropy:                                  -50850.90086300798\n",
      "KL between old and new distribution:      0.00988796139501634\n",
      "Surrogate loss:                           84561.91970524052\n",
      "\n",
      "********** Iteration 52 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -17.0037353969\n",
      "Std of rewards per episode:               19.130632734\n",
      "Entropy:                                  -50647.32076258801\n",
      "KL between old and new distribution:      0.009848780952129656\n",
      "Surrogate loss:                           86122.31422148383\n",
      "\n",
      "********** Iteration 53 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -16.7438288423\n",
      "Std of rewards per episode:               20.3974764051\n",
      "Entropy:                                  -50407.57920374501\n",
      "KL between old and new distribution:      0.009989147729316491\n",
      "Surrogate loss:                           85958.44788071196\n",
      "\n",
      "********** Iteration 54 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -16.6095819181\n",
      "Std of rewards per episode:               18.1727756515\n",
      "Entropy:                                  -50228.08075791836\n",
      "KL between old and new distribution:      0.009780649920528935\n",
      "Surrogate loss:                           85843.98266032545\n",
      "\n",
      "********** Iteration 55 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -15.5109065934\n",
      "Std of rewards per episode:               17.9895207468\n",
      "Entropy:                                  -50040.50801275171\n",
      "KL between old and new distribution:      0.009960765899894955\n",
      "Surrogate loss:                           80977.86975476217\n",
      "\n",
      "********** Iteration 56 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -15.9328361638\n",
      "Std of rewards per episode:               18.2818316458\n",
      "Entropy:                                  -49836.33220774157\n",
      "KL between old and new distribution:      0.009897043313080072\n",
      "Surrogate loss:                           80197.09526097316\n",
      "\n",
      "********** Iteration 57 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -15.6865274725\n",
      "Std of rewards per episode:               17.7282409378\n",
      "Entropy:                                  -49571.17687696149\n",
      "KL between old and new distribution:      0.009985002832982356\n",
      "Surrogate loss:                           80054.60072769871\n",
      "\n",
      "********** Iteration 58 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -15.3612964072\n",
      "Std of rewards per episode:               18.5940609358\n",
      "Entropy:                                  -49431.515561684566\n",
      "KL between old and new distribution:      0.009954488072346975\n",
      "Surrogate loss:                           78555.3670702551\n",
      "\n",
      "********** Iteration 59 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -14.2994398402\n",
      "Std of rewards per episode:               16.7269175803\n",
      "Entropy:                                  -49212.71109987304\n",
      "KL between old and new distribution:      0.009938928612090635\n",
      "Surrogate loss:                           74828.47350418879\n",
      "\n",
      "********** Iteration 60 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2001\n",
      "Average sum of rewards per episode:       -14.0044797601\n",
      "Std of rewards per episode:               18.7123308999\n",
      "Entropy:                                  -48950.26218316722\n",
      "KL between old and new distribution:      0.00990896688507928\n",
      "Surrogate loss:                           73175.23076419157\n",
      "\n",
      "********** Iteration 61 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -14.263992012\n",
      "Std of rewards per episode:               16.4872677467\n",
      "Entropy:                                  -48756.250361183535\n",
      "KL between old and new distribution:      0.009931125821714\n",
      "Surrogate loss:                           74398.54599541717\n",
      "\n",
      "********** Iteration 62 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2001\n",
      "Average sum of rewards per episode:       -14.3473768116\n",
      "Std of rewards per episode:               16.8585914295\n",
      "Entropy:                                  -48575.876104566814\n",
      "KL between old and new distribution:      0.009922484288895162\n",
      "Surrogate loss:                           74207.38185765989\n",
      "\n",
      "********** Iteration 63 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -13.7916556886\n",
      "Std of rewards per episode:               18.4901606062\n",
      "Entropy:                                  -48361.47484364145\n",
      "KL between old and new distribution:      0.00996206240238103\n",
      "Surrogate loss:                           71235.2982233442\n",
      "\n",
      "********** Iteration 64 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -13.6676969546\n",
      "Std of rewards per episode:               18.1502827856\n",
      "Entropy:                                  -48172.18309970641\n",
      "KL between old and new distribution:      0.00986285082408722\n",
      "Surrogate loss:                           69844.91761134323\n",
      "\n",
      "********** Iteration 65 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -14.0129410884\n",
      "Std of rewards per episode:               15.6040258366\n",
      "Entropy:                                  -47939.650454603565\n",
      "KL between old and new distribution:      0.009984125555292465\n",
      "Surrogate loss:                           72626.87802346973\n",
      "\n",
      "********** Iteration 66 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -13.4496399002\n",
      "Std of rewards per episode:               18.9312692994\n",
      "Entropy:                                  -47704.48044688401\n",
      "KL between old and new distribution:      0.009917485058148823\n",
      "Surrogate loss:                           69167.7849646045\n",
      "\n",
      "********** Iteration 67 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -12.1284049875\n",
      "Std of rewards per episode:               16.7082478719\n",
      "Entropy:                                  -47437.26395959941\n",
      "KL between old and new distribution:      0.009986243543836025\n",
      "Surrogate loss:                           63327.000118848286\n",
      "\n",
      "********** Iteration 68 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -12.5457741775\n",
      "Std of rewards per episode:               17.5060645704\n",
      "Entropy:                                  -47221.45888794549\n",
      "KL between old and new distribution:      0.009823881261718454\n",
      "Surrogate loss:                           65245.1437475764\n",
      "\n",
      "********** Iteration 69 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -12.9515933134\n",
      "Std of rewards per episode:               19.1154645845\n",
      "Entropy:                                  -47022.307140385004\n",
      "KL between old and new distribution:      0.00998470310594675\n",
      "Surrogate loss:                           66395.92648851234\n",
      "\n",
      "********** Iteration 70 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -13.0621196411\n",
      "Std of rewards per episode:               20.9707128385\n",
      "Entropy:                                  -46886.51028748901\n",
      "KL between old and new distribution:      0.009922152413208594\n",
      "Surrogate loss:                           66812.34037275544\n",
      "\n",
      "********** Iteration 71 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -12.6250904096\n",
      "Std of rewards per episode:               16.1722393134\n",
      "Entropy:                                  -46581.66533397818\n",
      "KL between old and new distribution:      0.009876003222185853\n",
      "Surrogate loss:                           65121.46611604918\n",
      "\n",
      "********** Iteration 72 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -11.8102045908\n",
      "Std of rewards per episode:               15.7833663282\n",
      "Entropy:                                  -46386.884005993204\n",
      "KL between old and new distribution:      0.009840859198403645\n",
      "Surrogate loss:                           60505.85456839013\n",
      "\n",
      "********** Iteration 73 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -12.4927543684\n",
      "Std of rewards per episode:               16.7813702268\n",
      "Entropy:                                  -46230.25925884975\n",
      "KL between old and new distribution:      0.00985089731980026\n",
      "Surrogate loss:                           63349.42216638001\n",
      "\n",
      "********** Iteration 74 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -11.8381003996\n",
      "Std of rewards per episode:               15.3790892763\n",
      "Entropy:                                  -46028.20726150296\n",
      "KL between old and new distribution:      0.009925129017070778\n",
      "Surrogate loss:                           61769.02296487946\n",
      "\n",
      "********** Iteration 75 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -12.1034310689\n",
      "Std of rewards per episode:               17.4377359819\n",
      "Entropy:                                  -45752.26182811608\n",
      "KL between old and new distribution:      0.009843092769763454\n",
      "Surrogate loss:                           61528.84762060926\n",
      "\n",
      "********** Iteration 76 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -11.635605985\n",
      "Std of rewards per episode:               19.2580259575\n",
      "Entropy:                                  -45617.58148928617\n",
      "KL between old and new distribution:      0.009994249524754304\n",
      "Surrogate loss:                           60956.26491386628\n",
      "\n",
      "********** Iteration 77 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -11.276955611\n",
      "Std of rewards per episode:               17.4999474025\n",
      "Entropy:                                  -45436.471747085314\n",
      "KL between old and new distribution:      0.009884630792621571\n",
      "Surrogate loss:                           59325.4173453458\n",
      "\n",
      "********** Iteration 78 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2001\n",
      "Average sum of rewards per episode:       -10.9145117441\n",
      "Std of rewards per episode:               18.4994666909\n",
      "Entropy:                                  -45138.08125533775\n",
      "KL between old and new distribution:      0.00995508744190477\n",
      "Surrogate loss:                           55764.19700974076\n",
      "\n",
      "********** Iteration 79 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -10.9851102794\n",
      "Std of rewards per episode:               16.1799006963\n",
      "Entropy:                                  -45001.52050834638\n",
      "KL between old and new distribution:      0.009927160493047607\n",
      "Surrogate loss:                           56116.37456542877\n",
      "\n",
      "********** Iteration 80 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -10.4870578554\n",
      "Std of rewards per episode:               17.4366791215\n",
      "Entropy:                                  -44751.762941898276\n",
      "KL between old and new distribution:      0.009964476268225983\n",
      "Surrogate loss:                           54714.32220807759\n",
      "\n",
      "********** Iteration 81 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -10.2474311377\n",
      "Std of rewards per episode:               17.4248988623\n",
      "Entropy:                                  -44550.42571340013\n",
      "KL between old and new distribution:      0.009958276739355974\n",
      "Surrogate loss:                           54001.50902952031\n",
      "\n",
      "********** Iteration 82 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2001\n",
      "Average sum of rewards per episode:       -11.1022603698\n",
      "Std of rewards per episode:               15.9580594651\n",
      "Entropy:                                  -44417.51457621384\n",
      "KL between old and new distribution:      0.009934006767872547\n",
      "Surrogate loss:                           56034.99038702656\n",
      "\n",
      "********** Iteration 83 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -11.1445773453\n",
      "Std of rewards per episode:               18.2655889848\n",
      "Entropy:                                  -44134.92699451507\n",
      "KL between old and new distribution:      0.00983694490233039\n",
      "Surrogate loss:                           55592.47281160335\n",
      "\n",
      "********** Iteration 84 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -10.258956044\n",
      "Std of rewards per episode:               18.3769374558\n",
      "Entropy:                                  -43942.56631996036\n",
      "KL between old and new distribution:      0.009904979181262815\n",
      "Surrogate loss:                           53471.7023014154\n",
      "\n",
      "********** Iteration 85 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -10.1707767233\n",
      "Std of rewards per episode:               17.6564405456\n",
      "Entropy:                                  -43694.255962227995\n",
      "KL between old and new distribution:      0.009963055668808648\n",
      "Surrogate loss:                           51330.012945912305\n",
      "\n",
      "********** Iteration 86 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -9.72942436345\n",
      "Std of rewards per episode:               15.3535162399\n",
      "Entropy:                                  -43493.59099408027\n",
      "KL between old and new distribution:      0.009969999370693561\n",
      "Surrogate loss:                           48944.951370401104\n",
      "\n",
      "********** Iteration 87 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -9.76521845387\n",
      "Std of rewards per episode:               15.9712301686\n",
      "Entropy:                                  -43253.39740461332\n",
      "KL between old and new distribution:      0.00982902537536394\n",
      "Surrogate loss:                           50100.28213550193\n",
      "\n",
      "********** Iteration 88 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -10.2025142287\n",
      "Std of rewards per episode:               15.6525495958\n",
      "Entropy:                                  -43020.32129563704\n",
      "KL between old and new distribution:      0.009829034125446426\n",
      "Surrogate loss:                           51034.37237875733\n",
      "\n",
      "********** Iteration 89 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -10.0799230769\n",
      "Std of rewards per episode:               14.8022029162\n",
      "Entropy:                                  -42857.240743140916\n",
      "KL between old and new distribution:      0.009918935504479698\n",
      "Surrogate loss:                           50956.73150048939\n",
      "\n",
      "********** Iteration 90 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2001\n",
      "Average sum of rewards per episode:       -9.22424987506\n",
      "Std of rewards per episode:               15.1688467911\n",
      "Entropy:                                  -42708.0122295575\n",
      "KL between old and new distribution:      0.009963548962402046\n",
      "Surrogate loss:                           49349.89466404385\n",
      "\n",
      "********** Iteration 91 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -8.63947531172\n",
      "Std of rewards per episode:               16.9098457431\n",
      "Entropy:                                  -42464.63418463643\n",
      "KL between old and new distribution:      0.009895052684699347\n",
      "Surrogate loss:                           45627.06804590641\n",
      "\n",
      "********** Iteration 92 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2007\n",
      "Average sum of rewards per episode:       -8.70742351769\n",
      "Std of rewards per episode:               17.2523665812\n",
      "Entropy:                                  -42232.97105140717\n",
      "KL between old and new distribution:      0.009883710721721211\n",
      "Surrogate loss:                           44752.91497354461\n",
      "\n",
      "********** Iteration 93 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -8.79019130869\n",
      "Std of rewards per episode:               17.4018402059\n",
      "Entropy:                                  -42094.09486016901\n",
      "KL between old and new distribution:      0.009899548873443477\n",
      "Surrogate loss:                           45728.382435859574\n",
      "\n",
      "********** Iteration 94 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -9.2756511976\n",
      "Std of rewards per episode:               17.6100177268\n",
      "Entropy:                                  -41793.73872753784\n",
      "KL between old and new distribution:      0.009805809588381315\n",
      "Surrogate loss:                           47405.26996257711\n",
      "\n",
      "********** Iteration 95 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -8.23057456359\n",
      "Std of rewards per episode:               15.9862713318\n",
      "Entropy:                                  -41628.1786231853\n",
      "KL between old and new distribution:      0.00989069109617213\n",
      "Surrogate loss:                           43764.67548641133\n",
      "\n",
      "********** Iteration 96 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2001\n",
      "Average sum of rewards per episode:       -8.7400049975\n",
      "Std of rewards per episode:               15.4686130622\n",
      "Entropy:                                  -41436.87222124375\n",
      "KL between old and new distribution:      0.009938405484568024\n",
      "Surrogate loss:                           44707.2038571878\n",
      "\n",
      "********** Iteration 97 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -8.16847802198\n",
      "Std of rewards per episode:               17.7800682375\n",
      "Entropy:                                  -41229.85323457786\n",
      "KL between old and new distribution:      0.009827317781395737\n",
      "Surrogate loss:                           42487.14518626284\n",
      "\n",
      "********** Iteration 98 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -7.87239232303\n",
      "Std of rewards per episode:               16.1929789275\n",
      "Entropy:                                  -40994.54353390689\n",
      "KL between old and new distribution:      0.00993684234616774\n",
      "Surrogate loss:                           40873.448688498574\n",
      "\n",
      "********** Iteration 99 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -7.51616267465\n",
      "Std of rewards per episode:               14.4840514947\n",
      "Entropy:                                  -40812.340441400345\n",
      "KL between old and new distribution:      0.009945227982368104\n",
      "Surrogate loss:                           39246.849013854844\n",
      "\n",
      "********** Iteration 100 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2007\n",
      "Average sum of rewards per episode:       -7.39567513702\n",
      "Std of rewards per episode:               14.7830627227\n",
      "Entropy:                                  -40592.49161137925\n",
      "KL between old and new distribution:      0.009921657991270231\n",
      "Surrogate loss:                           38887.719214808254\n",
      "\n",
      "********** Iteration 101 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -7.40579102244\n",
      "Std of rewards per episode:               15.361995229\n",
      "Entropy:                                  -40354.981517781685\n",
      "KL between old and new distribution:      0.009938566072121801\n",
      "Surrogate loss:                           38838.484085694974\n",
      "\n",
      "********** Iteration 102 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -7.18800399002\n",
      "Std of rewards per episode:               16.0790988115\n",
      "Entropy:                                  -40173.32320093003\n",
      "KL between old and new distribution:      0.00994353239357912\n",
      "Surrogate loss:                           38409.89514694778\n",
      "\n",
      "********** Iteration 103 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -6.98448702595\n",
      "Std of rewards per episode:               16.3152469856\n",
      "Entropy:                                  -39971.897610955864\n",
      "KL between old and new distribution:      0.009998928886024256\n",
      "Surrogate loss:                           37321.48477894291\n",
      "\n",
      "********** Iteration 104 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -6.37600399202\n",
      "Std of rewards per episode:               16.9835390549\n",
      "Entropy:                                  -39716.80704529971\n",
      "KL between old and new distribution:      0.009967162598261928\n",
      "Surrogate loss:                           33876.856923086074\n",
      "\n",
      "********** Iteration 105 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -6.59476035946\n",
      "Std of rewards per episode:               16.7377064636\n",
      "Entropy:                                  -39493.594889492684\n",
      "KL between old and new distribution:      0.00989177284230677\n",
      "Surrogate loss:                           34882.65919845082\n",
      "\n",
      "********** Iteration 106 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -6.41796410768\n",
      "Std of rewards per episode:               15.980497387\n",
      "Entropy:                                  -39399.51448911441\n",
      "KL between old and new distribution:      0.009978243822732253\n",
      "Surrogate loss:                           34642.75555124794\n",
      "\n",
      "********** Iteration 107 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2009\n",
      "Average sum of rewards per episode:       -6.09159930314\n",
      "Std of rewards per episode:               16.8337068494\n",
      "Entropy:                                  -39098.90225760316\n",
      "KL between old and new distribution:      0.009841983722451672\n",
      "Surrogate loss:                           33976.77779059342\n",
      "\n",
      "********** Iteration 108 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -6.1283042394\n",
      "Std of rewards per episode:               13.6807490082\n",
      "Entropy:                                  -38903.456921250334\n",
      "KL between old and new distribution:      0.009926277553814642\n",
      "Surrogate loss:                           33400.20923527981\n",
      "\n",
      "********** Iteration 109 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -6.46191916168\n",
      "Std of rewards per episode:               14.5358751376\n",
      "Entropy:                                  -38656.900119654674\n",
      "KL between old and new distribution:      0.009835991112167028\n",
      "Surrogate loss:                           33833.580751435395\n",
      "\n",
      "********** Iteration 110 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -5.85291072319\n",
      "Std of rewards per episode:               14.6471762009\n",
      "Entropy:                                  -38494.17887933439\n",
      "KL between old and new distribution:      0.009952570754851656\n",
      "Surrogate loss:                           31820.845378519607\n",
      "\n",
      "********** Iteration 111 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -5.85180159521\n",
      "Std of rewards per episode:               18.4878316705\n",
      "Entropy:                                  -38337.52723050321\n",
      "KL between old and new distribution:      0.009899622423712891\n",
      "Surrogate loss:                           31093.48857483417\n",
      "\n",
      "********** Iteration 112 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2007\n",
      "Average sum of rewards per episode:       -5.90955356253\n",
      "Std of rewards per episode:               17.3035050421\n",
      "Entropy:                                  -38174.59624087231\n",
      "KL between old and new distribution:      0.009954444618415098\n",
      "Surrogate loss:                           30638.74825488583\n",
      "\n",
      "********** Iteration 113 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -5.20076857855\n",
      "Std of rewards per episode:               16.8407102848\n",
      "Entropy:                                  -37878.580406776724\n",
      "KL between old and new distribution:      0.009873556524471166\n",
      "Surrogate loss:                           28266.507143631658\n",
      "\n",
      "********** Iteration 114 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2008\n",
      "Average sum of rewards per episode:       -5.35617280876\n",
      "Std of rewards per episode:               16.5390584613\n",
      "Entropy:                                  -37694.378302175595\n",
      "KL between old and new distribution:      0.009916498722912665\n",
      "Surrogate loss:                           28761.757334815386\n",
      "\n",
      "********** Iteration 115 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -5.55660219342\n",
      "Std of rewards per episode:               18.7110324624\n",
      "Entropy:                                  -37572.56960925926\n",
      "KL between old and new distribution:      0.009875601678653366\n",
      "Surrogate loss:                           30747.96320231905\n",
      "\n",
      "********** Iteration 116 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -5.7262656016\n",
      "Std of rewards per episode:               16.095339307\n",
      "Entropy:                                  -37332.21810766543\n",
      "KL between old and new distribution:      0.009861717942828006\n",
      "Surrogate loss:                           29516.469912176326\n",
      "\n",
      "********** Iteration 117 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2001\n",
      "Average sum of rewards per episode:       -5.24424437781\n",
      "Std of rewards per episode:               16.5506148947\n",
      "Entropy:                                  -37108.71300079974\n",
      "KL between old and new distribution:      0.009943983907165468\n",
      "Surrogate loss:                           26996.977449606366\n",
      "\n",
      "********** Iteration 118 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -6.00476696607\n",
      "Std of rewards per episode:               15.8919659171\n",
      "Entropy:                                  -36923.62944183375\n",
      "KL between old and new distribution:      0.009926117588913872\n",
      "Surrogate loss:                           29706.37848505106\n",
      "\n",
      "********** Iteration 119 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -4.84783774338\n",
      "Std of rewards per episode:               17.0006030935\n",
      "Entropy:                                  -36763.27279397441\n",
      "KL between old and new distribution:      0.009947173598891926\n",
      "Surrogate loss:                           26105.852670272347\n",
      "\n",
      "********** Iteration 120 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -5.25446433915\n",
      "Std of rewards per episode:               15.3978008907\n",
      "Entropy:                                  -36555.39210250982\n",
      "KL between old and new distribution:      0.00995942534267501\n",
      "Surrogate loss:                           28196.180512022085\n",
      "\n",
      "********** Iteration 121 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -5.03720687936\n",
      "Std of rewards per episode:               16.2488906483\n",
      "Entropy:                                  -36342.58756739099\n",
      "KL between old and new distribution:      0.009888753083834965\n",
      "Surrogate loss:                           27307.939825343878\n",
      "\n",
      "********** Iteration 122 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -4.67389381854\n",
      "Std of rewards per episode:               16.836703453\n",
      "Entropy:                                  -36101.321519132696\n",
      "KL between old and new distribution:      0.00996378698840005\n",
      "Surrogate loss:                           26472.629208832142\n",
      "\n",
      "********** Iteration 123 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2002\n",
      "Average sum of rewards per episode:       -5.14172877123\n",
      "Std of rewards per episode:               14.0241392551\n",
      "Entropy:                                  -35937.201284095594\n",
      "KL between old and new distribution:      0.00993453040177303\n",
      "Surrogate loss:                           26479.607774598164\n",
      "\n",
      "********** Iteration 124 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -4.58034214464\n",
      "Std of rewards per episode:               16.7851796928\n",
      "Entropy:                                  -35733.13166096422\n",
      "KL between old and new distribution:      0.009981013093230443\n",
      "Surrogate loss:                           25789.238057577684\n",
      "\n",
      "********** Iteration 125 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -5.49817174239\n",
      "Std of rewards per episode:               16.4502452359\n",
      "Entropy:                                  -35521.02818867285\n",
      "KL between old and new distribution:      0.009843629606179948\n",
      "Surrogate loss:                           27420.14884010494\n",
      "\n",
      "********** Iteration 126 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -5.12687930175\n",
      "Std of rewards per episode:               14.2278327313\n",
      "Entropy:                                  -35326.29790614039\n",
      "KL between old and new distribution:      0.009919156634289276\n",
      "Surrogate loss:                           26056.850964952733\n",
      "\n",
      "********** Iteration 127 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -3.79579551122\n",
      "Std of rewards per episode:               17.2877912548\n",
      "Entropy:                                  -35190.830385393114\n",
      "KL between old and new distribution:      0.009957917834829421\n",
      "Surrogate loss:                           22708.56568561142\n",
      "\n",
      "********** Iteration 128 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -4.5430508982\n",
      "Std of rewards per episode:               13.6076464251\n",
      "Entropy:                                  -34923.63184713021\n",
      "KL between old and new distribution:      0.009937622607029984\n",
      "Surrogate loss:                           23761.75355400991\n",
      "\n",
      "********** Iteration 129 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2007\n",
      "Average sum of rewards per episode:       -4.43707274539\n",
      "Std of rewards per episode:               15.6794328779\n",
      "Entropy:                                  -34748.51483094135\n",
      "KL between old and new distribution:      0.009962730918367232\n",
      "Surrogate loss:                           23527.507675188383\n",
      "\n",
      "********** Iteration 130 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -3.89581977034\n",
      "Std of rewards per episode:               16.636031811\n",
      "Entropy:                                  -34580.195319439044\n",
      "KL between old and new distribution:      0.009937973769870132\n",
      "Surrogate loss:                           21523.01145849823\n",
      "\n",
      "********** Iteration 131 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -4.38335728543\n",
      "Std of rewards per episode:               14.7216488973\n",
      "Entropy:                                  -34338.66646483761\n",
      "KL between old and new distribution:      0.009886628402670057\n",
      "Surrogate loss:                           23672.765057240533\n",
      "\n",
      "********** Iteration 132 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -3.98514021956\n",
      "Std of rewards per episode:               15.8217688354\n",
      "Entropy:                                  -34149.44875778662\n",
      "KL between old and new distribution:      0.009944051283508623\n",
      "Surrogate loss:                           22409.555721890953\n",
      "\n",
      "********** Iteration 133 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2007\n",
      "Average sum of rewards per episode:       -3.71407772795\n",
      "Std of rewards per episode:               17.6207353768\n",
      "Entropy:                                  -33987.73560010819\n",
      "KL between old and new distribution:      0.009890905264856961\n",
      "Surrogate loss:                           20813.835867419162\n",
      "\n",
      "********** Iteration 134 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -3.70362724551\n",
      "Std of rewards per episode:               13.5026099902\n",
      "Entropy:                                  -33824.577566203814\n",
      "KL between old and new distribution:      0.009996402599308809\n",
      "Surrogate loss:                           19462.19179612503\n",
      "\n",
      "********** Iteration 135 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -4.18661216351\n",
      "Std of rewards per episode:               16.5415283508\n",
      "Entropy:                                  -33644.02174045487\n",
      "KL between old and new distribution:      0.009943667404944949\n",
      "Surrogate loss:                           21220.789175791495\n",
      "\n",
      "********** Iteration 136 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -4.07829141717\n",
      "Std of rewards per episode:               12.6237472333\n",
      "Entropy:                                  -33448.01508366082\n",
      "KL between old and new distribution:      0.00993308277094217\n",
      "Surrogate loss:                           21532.33146422118\n",
      "\n",
      "********** Iteration 137 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -3.34828443114\n",
      "Std of rewards per episode:               16.8450453634\n",
      "Entropy:                                  -33294.34133774143\n",
      "KL between old and new distribution:      0.009954158646916908\n",
      "Surrogate loss:                           19042.330437720095\n",
      "\n",
      "********** Iteration 138 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2012\n",
      "Average sum of rewards per episode:       -3.27311928429\n",
      "Std of rewards per episode:               19.8021606096\n",
      "Entropy:                                  -33069.86306869408\n",
      "KL between old and new distribution:      0.0099320877872193\n",
      "Surrogate loss:                           19148.44676530975\n",
      "\n",
      "********** Iteration 139 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -3.73645164506\n",
      "Std of rewards per episode:               15.1220500594\n",
      "Entropy:                                  -32907.47777626578\n",
      "KL between old and new distribution:      0.009958347893908226\n",
      "Surrogate loss:                           19982.64002600177\n",
      "\n",
      "********** Iteration 140 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -3.34698553616\n",
      "Std of rewards per episode:               16.4005391911\n",
      "Entropy:                                  -32708.770653851345\n",
      "KL between old and new distribution:      0.0099048856161443\n",
      "Surrogate loss:                           19394.93924425794\n",
      "\n",
      "********** Iteration 141 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -2.27366583541\n",
      "Std of rewards per episode:               20.2227348629\n",
      "Entropy:                                  -32586.408513970076\n",
      "KL between old and new distribution:      0.009953250054415613\n",
      "Surrogate loss:                           13627.426606557807\n",
      "\n",
      "********** Iteration 142 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2003\n",
      "Average sum of rewards per episode:       -3.14563804294\n",
      "Std of rewards per episode:               13.4074974923\n",
      "Entropy:                                  -32399.44090624356\n",
      "KL between old and new distribution:      0.009874983757468894\n",
      "Surrogate loss:                           17849.878038403374\n",
      "\n",
      "********** Iteration 143 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -2.46188683948\n",
      "Std of rewards per episode:               17.654270838\n",
      "Entropy:                                  -32221.90518995631\n",
      "KL between old and new distribution:      0.00998415872473076\n",
      "Surrogate loss:                           13738.612891262987\n",
      "\n",
      "********** Iteration 144 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -3.20786583541\n",
      "Std of rewards per episode:               17.1001438502\n",
      "Entropy:                                  -32121.41237977058\n",
      "KL between old and new distribution:      0.009878954311838517\n",
      "Surrogate loss:                           18542.920345577782\n",
      "\n",
      "********** Iteration 145 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2011\n",
      "Average sum of rewards per episode:       -2.45421631029\n",
      "Std of rewards per episode:               22.0545012949\n",
      "Entropy:                                  -31896.189395414785\n",
      "KL between old and new distribution:      0.009961531287592282\n",
      "Surrogate loss:                           15085.260567759702\n",
      "\n",
      "********** Iteration 146 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -2.71254137587\n",
      "Std of rewards per episode:               15.4910654635\n",
      "Entropy:                                  -31740.973104682864\n",
      "KL between old and new distribution:      0.009981557809190281\n",
      "Surrogate loss:                           16504.21837360748\n",
      "\n",
      "********** Iteration 147 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -3.01320498753\n",
      "Std of rewards per episode:               15.182638282\n",
      "Entropy:                                  -31493.405294854274\n",
      "KL between old and new distribution:      0.00989837100473819\n",
      "Surrogate loss:                           15634.666051509737\n",
      "\n",
      "********** Iteration 148 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2008\n",
      "Average sum of rewards per episode:       -3.37041384462\n",
      "Std of rewards per episode:               17.0472319695\n",
      "Entropy:                                  -31364.552306433343\n",
      "KL between old and new distribution:      0.009939908889371487\n",
      "Surrogate loss:                           16913.554614732824\n",
      "\n",
      "********** Iteration 149 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2005\n",
      "Average sum of rewards per episode:       -2.80108229426\n",
      "Std of rewards per episode:               17.8805336667\n",
      "Entropy:                                  -31165.082903136983\n",
      "KL between old and new distribution:      0.009900981692737445\n",
      "Surrogate loss:                           13770.007573171864\n",
      "\n",
      "********** Iteration 150 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2008\n",
      "Average sum of rewards per episode:       -3.05206324701\n",
      "Std of rewards per episode:               16.7983678657\n",
      "Entropy:                                  -31029.308590239583\n",
      "KL between old and new distribution:      0.00997536050777761\n",
      "Surrogate loss:                           17131.348826157413\n",
      "\n",
      "********** Iteration 151 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2008\n",
      "Average sum of rewards per episode:       -2.66146912351\n",
      "Std of rewards per episode:               17.3600196923\n",
      "Entropy:                                  -30820.327545566524\n",
      "KL between old and new distribution:      0.009996865958471553\n",
      "Surrogate loss:                           14493.540600670949\n",
      "\n",
      "********** Iteration 152 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2011\n",
      "Average sum of rewards per episode:       -2.39943659871\n",
      "Std of rewards per episode:               18.9838529685\n",
      "Entropy:                                  -30634.836002804157\n",
      "KL between old and new distribution:      0.009959310500038652\n",
      "Surrogate loss:                           14356.20590344874\n",
      "\n",
      "********** Iteration 153 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2004\n",
      "Average sum of rewards per episode:       -2.56492065868\n",
      "Std of rewards per episode:               14.3891160145\n",
      "Entropy:                                  -30471.125034415065\n",
      "KL between old and new distribution:      0.009964053856609107\n",
      "Surrogate loss:                           14239.490541004769\n",
      "\n",
      "********** Iteration 154 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2011\n",
      "Average sum of rewards per episode:       -2.21709845848\n",
      "Std of rewards per episode:               20.552959774\n",
      "Entropy:                                  -30359.563409893577\n",
      "KL between old and new distribution:      0.009922873705715061\n",
      "Surrogate loss:                           13098.973934854583\n",
      "\n",
      "********** Iteration 155 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2013\n",
      "Average sum of rewards per episode:       -1.52114406359\n",
      "Std of rewards per episode:               21.9400494212\n",
      "Entropy:                                  -30184.3418548272\n",
      "KL between old and new distribution:      0.009927271161511176\n",
      "Surrogate loss:                           10156.982128623926\n",
      "\n",
      "********** Iteration 156 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2010\n",
      "Average sum of rewards per episode:       -2.06888059701\n",
      "Std of rewards per episode:               22.4636842815\n",
      "Entropy:                                  -29986.632997263394\n",
      "KL between old and new distribution:      0.009997444925820486\n",
      "Surrogate loss:                           12390.12980420226\n",
      "\n",
      "********** Iteration 157 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2014\n",
      "Average sum of rewards per episode:       -1.87755362463\n",
      "Std of rewards per episode:               24.1912941194\n",
      "Entropy:                                  -29852.756272905317\n",
      "KL between old and new distribution:      0.009990649436297318\n",
      "Surrogate loss:                           10112.400852031575\n",
      "\n",
      "********** Iteration 158 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2013\n",
      "Average sum of rewards per episode:       -2.06759264779\n",
      "Std of rewards per episode:               22.933932511\n",
      "Entropy:                                  -29692.34610312168\n",
      "KL between old and new distribution:      0.009971572612709919\n",
      "Surrogate loss:                           12687.152063585936\n",
      "\n",
      "********** Iteration 159 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2006\n",
      "Average sum of rewards per episode:       -1.87363659023\n",
      "Std of rewards per episode:               21.619811586\n",
      "Entropy:                                  -29559.63391727663\n",
      "KL between old and new distribution:      0.00994192427219496\n",
      "Surrogate loss:                           10260.738771678753\n",
      "\n",
      "********** Iteration 160 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2013\n",
      "Average sum of rewards per episode:       -1.30177545951\n",
      "Std of rewards per episode:               23.6698629443\n",
      "Entropy:                                  -29297.658640498234\n",
      "KL between old and new distribution:      0.009953863451205882\n",
      "Surrogate loss:                           9502.151756604655\n",
      "\n",
      "********** Iteration 161 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2011\n",
      "Average sum of rewards per episode:       -1.54585678767\n",
      "Std of rewards per episode:               24.2438560519\n",
      "Entropy:                                  -29191.52366326838\n",
      "KL between old and new distribution:      0.009956233846054811\n",
      "Surrogate loss:                           8567.27421773808\n",
      "\n",
      "********** Iteration 162 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2013\n",
      "Average sum of rewards per episode:       -2.02446795827\n",
      "Std of rewards per episode:               20.5905142702\n",
      "Entropy:                                  -29010.844956604902\n",
      "KL between old and new distribution:      0.009909382802396487\n",
      "Surrogate loss:                           12803.163828553135\n",
      "\n",
      "********** Iteration 163 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2009\n",
      "Average sum of rewards per episode:       -1.72840617222\n",
      "Std of rewards per episode:               22.2999500397\n",
      "Entropy:                                  -28799.959862916254\n",
      "KL between old and new distribution:      0.009933054982667605\n",
      "Surrogate loss:                           7784.570963491756\n",
      "\n",
      "********** Iteration 164 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2016\n",
      "Average sum of rewards per episode:       -0.462285218254\n",
      "Std of rewards per episode:               26.0700330168\n",
      "Entropy:                                  -28609.53379738846\n",
      "KL between old and new distribution:      0.009914051989298029\n",
      "Surrogate loss:                           3293.091502052759\n",
      "\n",
      "********** Iteration 165 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2022\n",
      "Average sum of rewards per episode:       -0.456278437191\n",
      "Std of rewards per episode:               27.5879734893\n",
      "Entropy:                                  -28514.722130495713\n",
      "KL between old and new distribution:      0.009944199607418259\n",
      "Surrogate loss:                           5090.549496468368\n",
      "\n",
      "********** Iteration 166 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2016\n",
      "Average sum of rewards per episode:       -0.612845238095\n",
      "Std of rewards per episode:               27.917671876\n",
      "Entropy:                                  -28329.1002271393\n",
      "KL between old and new distribution:      0.009907648043947852\n",
      "Surrogate loss:                           4458.28621796202\n",
      "\n",
      "********** Iteration 167 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2018\n",
      "Average sum of rewards per episode:       0.133594152626\n",
      "Std of rewards per episode:               31.0549745652\n",
      "Entropy:                                  -28109.975597469034\n",
      "KL between old and new distribution:      0.00995954090434174\n",
      "Surrogate loss:                           1451.0715410141433\n",
      "\n",
      "********** Iteration 168 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2015\n",
      "Average sum of rewards per episode:       -0.138691811414\n",
      "Std of rewards per episode:               25.887435408\n",
      "Entropy:                                  -27964.198923273067\n",
      "KL between old and new distribution:      0.009984913466822615\n",
      "Surrogate loss:                           1689.665441516965\n",
      "\n",
      "********** Iteration 169 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2021\n",
      "Average sum of rewards per episode:       0.403199406235\n",
      "Std of rewards per episode:               27.7802582175\n",
      "Entropy:                                  -27747.3528415875\n",
      "KL between old and new distribution:      0.009965296610898386\n",
      "Surrogate loss:                           -2017.7990206827265\n",
      "\n",
      "********** Iteration 170 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2018\n",
      "Average sum of rewards per episode:       0.795729435084\n",
      "Std of rewards per episode:               31.6787991423\n",
      "Entropy:                                  -27450.062472704427\n",
      "KL between old and new distribution:      0.009948582746191382\n",
      "Surrogate loss:                           -5021.153549706828\n",
      "\n",
      "********** Iteration 171 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2023\n",
      "Average sum of rewards per episode:       1.25647305981\n",
      "Std of rewards per episode:               31.2961371873\n",
      "Entropy:                                  -27212.056018904146\n",
      "KL between old and new distribution:      0.009925077755453511\n",
      "Surrogate loss:                           -9894.794074894748\n",
      "\n",
      "********** Iteration 172 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2037\n",
      "Average sum of rewards per episode:       2.70152086402\n",
      "Std of rewards per episode:               37.0542328584\n",
      "Entropy:                                  -26962.086485263088\n",
      "KL between old and new distribution:      0.009909778533163263\n",
      "Surrogate loss:                           -16333.4717506264\n",
      "\n",
      "********** Iteration 173 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2045\n",
      "Average sum of rewards per episode:       4.16830855746\n",
      "Std of rewards per episode:               41.2788675019\n",
      "Entropy:                                  -26601.508465514522\n",
      "KL between old and new distribution:      0.00990502145167468\n",
      "Surrogate loss:                           -24118.559675708835\n",
      "\n",
      "********** Iteration 174 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2038\n",
      "Average sum of rewards per episode:       3.36700539745\n",
      "Std of rewards per episode:               40.1650912127\n",
      "Entropy:                                  -26432.078486855324\n",
      "KL between old and new distribution:      0.009965012485808684\n",
      "Surrogate loss:                           -17190.46529781605\n",
      "\n",
      "********** Iteration 175 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2034\n",
      "Average sum of rewards per episode:       2.86755703048\n",
      "Std of rewards per episode:               36.1312627189\n",
      "Entropy:                                  -26202.04856598516\n",
      "KL between old and new distribution:      0.009936034835497777\n",
      "Surrogate loss:                           -20110.163397220225\n",
      "\n",
      "********** Iteration 176 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2029\n",
      "Average sum of rewards per episode:       4.03669245934\n",
      "Std of rewards per episode:               39.8891098837\n",
      "Entropy:                                  -25887.753411844285\n",
      "KL between old and new distribution:      0.009904555953589803\n",
      "Surrogate loss:                           -21695.770980462392\n",
      "\n",
      "********** Iteration 177 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2041\n",
      "Average sum of rewards per episode:       5.1105144537\n",
      "Std of rewards per episode:               42.6729885382\n",
      "Entropy:                                  -25592.19067354486\n",
      "KL between old and new distribution:      0.009905193604782595\n",
      "Surrogate loss:                           -30594.347657403057\n",
      "\n",
      "********** Iteration 178 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2052\n",
      "Average sum of rewards per episode:       7.04588206628\n",
      "Std of rewards per episode:               45.3746255154\n",
      "Entropy:                                  -25113.716540833997\n",
      "KL between old and new distribution:      0.009956190926331144\n",
      "Surrogate loss:                           -36468.8469832249\n",
      "\n",
      "********** Iteration 179 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2041\n",
      "Average sum of rewards per episode:       6.62329495345\n",
      "Std of rewards per episode:               43.5854382414\n",
      "Entropy:                                  -24871.705205112026\n",
      "KL between old and new distribution:      0.00988285140060799\n",
      "Surrogate loss:                           -38931.90407283917\n",
      "\n",
      "********** Iteration 180 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2052\n",
      "Average sum of rewards per episode:       6.92176413255\n",
      "Std of rewards per episode:               42.9450337119\n",
      "Entropy:                                  -24776.472724748175\n",
      "KL between old and new distribution:      0.009956406395179893\n",
      "Surrogate loss:                           -37055.58670945558\n",
      "\n",
      "********** Iteration 181 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2050\n",
      "Average sum of rewards per episode:       4.36598585366\n",
      "Std of rewards per episode:               40.6021643666\n",
      "Entropy:                                  -24299.77307655883\n",
      "KL between old and new distribution:      0.009986373628127052\n",
      "Surrogate loss:                           -21429.710785725405\n",
      "\n",
      "********** Iteration 182 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2065\n",
      "Average sum of rewards per episode:       9.13887021792\n",
      "Std of rewards per episode:               49.0229453597\n",
      "Entropy:                                  -24156.697683918956\n",
      "KL between old and new distribution:      0.009942190093375568\n",
      "Surrogate loss:                           -52256.76473585566\n",
      "\n",
      "********** Iteration 183 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2080\n",
      "Average sum of rewards per episode:       12.4690745192\n",
      "Std of rewards per episode:               61.4338936153\n",
      "Entropy:                                  -23197.441185530457\n",
      "KL between old and new distribution:      0.00996283246557951\n",
      "Surrogate loss:                           -72397.27726127373\n",
      "\n",
      "********** Iteration 184 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2073\n",
      "Average sum of rewards per episode:       11.7852402315\n",
      "Std of rewards per episode:               56.3446911438\n",
      "Entropy:                                  -23255.41904492181\n",
      "KL between old and new distribution:      0.009950386161652378\n",
      "Surrogate loss:                           -67333.36281528833\n",
      "\n",
      "********** Iteration 185 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2071\n",
      "Average sum of rewards per episode:       10.209665379\n",
      "Std of rewards per episode:               51.5526171027\n",
      "Entropy:                                  -23025.545055135513\n",
      "KL between old and new distribution:      0.009887998947826097\n",
      "Surrogate loss:                           -58758.33785839244\n",
      "\n",
      "********** Iteration 186 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2072\n",
      "Average sum of rewards per episode:       13.5892181467\n",
      "Std of rewards per episode:               59.338813648\n",
      "Entropy:                                  -21994.212591753203\n",
      "KL between old and new distribution:      0.009830002522406109\n",
      "Surrogate loss:                           -75948.95183370738\n",
      "\n",
      "********** Iteration 187 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2105\n",
      "Average sum of rewards per episode:       16.1331752969\n",
      "Std of rewards per episode:               64.1267073456\n",
      "Entropy:                                  -21726.239425289503\n",
      "KL between old and new distribution:      0.009947102129866738\n",
      "Surrogate loss:                           -85174.93272952034\n",
      "\n",
      "********** Iteration 188 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2098\n",
      "Average sum of rewards per episode:       18.7955386082\n",
      "Std of rewards per episode:               67.7325398211\n",
      "Entropy:                                  -21353.83261861727\n",
      "KL between old and new distribution:      0.009895306823104215\n",
      "Surrogate loss:                           -103210.34513145014\n",
      "\n",
      "********** Iteration 189 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2090\n",
      "Average sum of rewards per episode:       19.9315688995\n",
      "Std of rewards per episode:               69.519831039\n",
      "Entropy:                                  -20842.99201184245\n",
      "KL between old and new distribution:      0.009899015609597257\n",
      "Surrogate loss:                           -112564.69446610134\n",
      "\n",
      "********** Iteration 190 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2116\n",
      "Average sum of rewards per episode:       19.181289225\n",
      "Std of rewards per episode:               70.6864909722\n",
      "Entropy:                                  -20381.036916103483\n",
      "KL between old and new distribution:      0.009938423201841875\n",
      "Surrogate loss:                           -107034.62450071599\n",
      "\n",
      "********** Iteration 191 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2128\n",
      "Average sum of rewards per episode:       22.7232091165\n",
      "Std of rewards per episode:               72.7541042688\n",
      "Entropy:                                  -19518.93478701595\n",
      "KL between old and new distribution:      0.009875859238125369\n",
      "Surrogate loss:                           -129575.2346532816\n",
      "\n",
      "********** Iteration 192 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2122\n",
      "Average sum of rewards per episode:       22.0272492931\n",
      "Std of rewards per episode:               71.303551541\n",
      "Entropy:                                  -19354.308797860936\n",
      "KL between old and new distribution:      0.009910994829333858\n",
      "Surrogate loss:                           -119213.62135604766\n",
      "\n",
      "********** Iteration 193 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2130\n",
      "Average sum of rewards per episode:       23.6596666667\n",
      "Std of rewards per episode:               72.5584557474\n",
      "Entropy:                                  -18979.679813243096\n",
      "KL between old and new distribution:      0.009952711151959344\n",
      "Surrogate loss:                           -137304.00998051342\n",
      "\n",
      "********** Iteration 194 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2142\n",
      "Average sum of rewards per episode:       28.4284243697\n",
      "Std of rewards per episode:               81.3709941156\n",
      "Entropy:                                  -18292.88322072184\n",
      "KL between old and new distribution:      0.00984702160994175\n",
      "Surrogate loss:                           -158348.9627145647\n",
      "\n",
      "********** Iteration 195 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2140\n",
      "Average sum of rewards per episode:       24.5709313084\n",
      "Std of rewards per episode:               76.9778271636\n",
      "Entropy:                                  -17773.436292531456\n",
      "KL between old and new distribution:      0.009938562298399888\n",
      "Surrogate loss:                           -140751.70966688334\n",
      "\n",
      "********** Iteration 196 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2152\n",
      "Average sum of rewards per episode:       27.6885051115\n",
      "Std of rewards per episode:               78.9649555125\n",
      "Entropy:                                  -17284.62022466218\n",
      "KL between old and new distribution:      0.009931843753826658\n",
      "Surrogate loss:                           -155303.0880784655\n",
      "\n",
      "********** Iteration 197 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2144\n",
      "Average sum of rewards per episode:       28.5533973881\n",
      "Std of rewards per episode:               80.5329537513\n",
      "Entropy:                                  -17164.32944523841\n",
      "KL between old and new distribution:      0.009956693337629463\n",
      "Surrogate loss:                           -158248.5632471377\n",
      "\n",
      "********** Iteration 198 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2171\n",
      "Average sum of rewards per episode:       32.8734900967\n",
      "Std of rewards per episode:               85.9682025686\n",
      "Entropy:                                  -16436.49609774331\n",
      "KL between old and new distribution:      0.009917959445401777\n",
      "Surrogate loss:                           -184083.40147066023\n",
      "\n",
      "********** Iteration 199 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2179\n",
      "Average sum of rewards per episode:       35.7346512162\n",
      "Std of rewards per episode:               88.2187424685\n",
      "Entropy:                                  -15885.123776127231\n",
      "KL between old and new distribution:      0.00999805546616868\n",
      "Surrogate loss:                           -213771.88647898933\n",
      "\n",
      "********** Iteration 200 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2182\n",
      "Average sum of rewards per episode:       34.3864802933\n",
      "Std of rewards per episode:               88.4291207401\n",
      "Entropy:                                  -15687.915679506335\n",
      "KL between old and new distribution:      0.009869188398159775\n",
      "Surrogate loss:                           -194200.77386842723\n",
      "\n",
      "********** Iteration 201 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2201\n",
      "Average sum of rewards per episode:       37.9753643798\n",
      "Std of rewards per episode:               91.7027281293\n",
      "Entropy:                                  -14856.435160307943\n",
      "KL between old and new distribution:      0.009948288381328357\n",
      "Surrogate loss:                           -216095.9175317162\n",
      "\n",
      "********** Iteration 202 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2180\n",
      "Average sum of rewards per episode:       37.2443142202\n",
      "Std of rewards per episode:               90.2498423839\n",
      "Entropy:                                  -14596.062397598816\n",
      "KL between old and new distribution:      0.009988598971025872\n",
      "Surrogate loss:                           -217898.4093391263\n",
      "\n",
      "********** Iteration 203 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2195\n",
      "Average sum of rewards per episode:       39.8746382688\n",
      "Std of rewards per episode:               92.5926938953\n",
      "Entropy:                                  -13952.484565662255\n",
      "KL between old and new distribution:      0.00985373726263681\n",
      "Surrogate loss:                           -234830.0001556935\n",
      "\n",
      "********** Iteration 204 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2193\n",
      "Average sum of rewards per episode:       41.015750114\n",
      "Std of rewards per episode:               94.7056558939\n",
      "Entropy:                                  -13594.574511282253\n",
      "KL between old and new distribution:      0.009915717645612308\n",
      "Surrogate loss:                           -232882.37737893488\n",
      "\n",
      "********** Iteration 205 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2206\n",
      "Average sum of rewards per episode:       44.3282674524\n",
      "Std of rewards per episode:               98.7053201383\n",
      "Entropy:                                  -12690.646082423642\n",
      "KL between old and new distribution:      0.009870718039202543\n",
      "Surrogate loss:                           -264212.72736798215\n",
      "\n",
      "********** Iteration 206 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2233\n",
      "Average sum of rewards per episode:       45.2370201523\n",
      "Std of rewards per episode:               97.714348505\n",
      "Entropy:                                  -12600.574849426626\n",
      "KL between old and new distribution:      0.009992697610070886\n",
      "Surrogate loss:                           -265168.37816979905\n",
      "\n",
      "********** Iteration 207 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2243\n",
      "Average sum of rewards per episode:       45.7787846634\n",
      "Std of rewards per episode:               98.2342921126\n",
      "Entropy:                                  -11570.944401502025\n",
      "KL between old and new distribution:      0.009857823656341176\n",
      "Surrogate loss:                           -267656.0936247301\n",
      "\n",
      "********** Iteration 208 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2237\n",
      "Average sum of rewards per episode:       46.0804009835\n",
      "Std of rewards per episode:               97.7197342445\n",
      "Entropy:                                  -11572.066214421238\n",
      "KL between old and new distribution:      0.009949142026239779\n",
      "Surrogate loss:                           -261801.8267316609\n",
      "\n",
      "********** Iteration 209 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2250\n",
      "Average sum of rewards per episode:       50.242008\n",
      "Std of rewards per episode:               102.936912241\n",
      "Entropy:                                  -11320.612939687177\n",
      "KL between old and new distribution:      0.00999258806738443\n",
      "Surrogate loss:                           -290399.51534447743\n",
      "\n",
      "********** Iteration 210 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2303\n",
      "Average sum of rewards per episode:       58.1742974381\n",
      "Std of rewards per episode:               111.980630549\n",
      "Entropy:                                  -10254.239989493512\n",
      "KL between old and new distribution:      0.009935919628155921\n",
      "Surrogate loss:                           -347066.02194896684\n",
      "\n",
      "********** Iteration 211 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2286\n",
      "Average sum of rewards per episode:       57.0289728784\n",
      "Std of rewards per episode:               107.789319973\n",
      "Entropy:                                  -9553.70914194577\n",
      "KL between old and new distribution:      0.009848191527230276\n",
      "Surrogate loss:                           -334735.9959646073\n",
      "\n",
      "********** Iteration 212 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2288\n",
      "Average sum of rewards per episode:       58.3701822552\n",
      "Std of rewards per episode:               111.190523239\n",
      "Entropy:                                  -9465.027461261789\n",
      "KL between old and new distribution:      0.009881591360697854\n",
      "Surrogate loss:                           -352095.05328615295\n",
      "\n",
      "********** Iteration 213 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2289\n",
      "Average sum of rewards per episode:       55.2756168633\n",
      "Std of rewards per episode:               106.44642251\n",
      "Entropy:                                  -9370.45907263399\n",
      "KL between old and new distribution:      0.009946105247597144\n",
      "Surrogate loss:                           -331708.7942699473\n",
      "\n",
      "********** Iteration 214 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2329\n",
      "Average sum of rewards per episode:       63.0693997424\n",
      "Std of rewards per episode:               110.974899087\n",
      "Entropy:                                  -8412.24049284162\n",
      "KL between old and new distribution:      0.009893951222266394\n",
      "Surrogate loss:                           -381387.4573175848\n",
      "\n",
      "********** Iteration 215 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2331\n",
      "Average sum of rewards per episode:       64.1568060918\n",
      "Std of rewards per episode:               116.039414279\n",
      "Entropy:                                  -7721.386829730922\n",
      "KL between old and new distribution:      0.00982458761710186\n",
      "Surrogate loss:                           -390064.10742734506\n",
      "\n",
      "********** Iteration 216 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2355\n",
      "Average sum of rewards per episode:       69.661259448\n",
      "Std of rewards per episode:               116.235498878\n",
      "Entropy:                                  -7004.110080207433\n",
      "KL between old and new distribution:      0.009849832006674601\n",
      "Surrogate loss:                           -422677.3768166608\n",
      "\n",
      "********** Iteration 217 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2341\n",
      "Average sum of rewards per episode:       72.865183255\n",
      "Std of rewards per episode:               121.997075173\n",
      "Entropy:                                  -6928.691125917423\n",
      "KL between old and new distribution:      0.009990346991349515\n",
      "Surrogate loss:                           -450135.56591642083\n",
      "\n",
      "********** Iteration 218 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2352\n",
      "Average sum of rewards per episode:       70.6048839286\n",
      "Std of rewards per episode:               118.415314992\n",
      "Entropy:                                  -6108.676389610014\n",
      "KL between old and new distribution:      0.009885258382811561\n",
      "Surrogate loss:                           -433820.39149679267\n",
      "\n",
      "********** Iteration 219 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2361\n",
      "Average sum of rewards per episode:       71.6366637018\n",
      "Std of rewards per episode:               120.001994019\n",
      "Entropy:                                  -6490.157829701214\n",
      "KL between old and new distribution:      0.009928095244056724\n",
      "Surrogate loss:                           -426349.4678284657\n",
      "\n",
      "********** Iteration 220 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2354\n",
      "Average sum of rewards per episode:       70.0157374681\n",
      "Std of rewards per episode:               118.172865431\n",
      "Entropy:                                  -5353.888853814237\n",
      "KL between old and new distribution:      0.009938743403132758\n",
      "Surrogate loss:                           -430372.02876765927\n",
      "\n",
      "********** Iteration 221 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2422\n",
      "Average sum of rewards per episode:       77.8680763832\n",
      "Std of rewards per episode:               122.885647904\n",
      "Entropy:                                  -5257.260656257055\n",
      "KL between old and new distribution:      0.009975043317666268\n",
      "Surrogate loss:                           -468800.6298349135\n",
      "\n",
      "********** Iteration 222 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2403\n",
      "Average sum of rewards per episode:       80.168758635\n",
      "Std of rewards per episode:               123.285373271\n",
      "Entropy:                                  -5131.244193710644\n",
      "KL between old and new distribution:      0.009865525277982293\n",
      "Surrogate loss:                           -503528.25947347155\n",
      "\n",
      "********** Iteration 223 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2439\n",
      "Average sum of rewards per episode:       84.3588642886\n",
      "Std of rewards per episode:               127.982471135\n",
      "Entropy:                                  -4596.580632019972\n",
      "KL between old and new distribution:      0.009813476902347226\n",
      "Surrogate loss:                           -514115.56009281025\n",
      "\n",
      "********** Iteration 224 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2440\n",
      "Average sum of rewards per episode:       84.750322541\n",
      "Std of rewards per episode:               124.866429927\n",
      "Entropy:                                  -3627.788935764898\n",
      "KL between old and new distribution:      0.009940733162938567\n",
      "Surrogate loss:                           -531887.3976134444\n",
      "\n",
      "********** Iteration 225 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2450\n",
      "Average sum of rewards per episode:       82.7996028571\n",
      "Std of rewards per episode:               126.620804887\n",
      "Entropy:                                  -3103.1876430921366\n",
      "KL between old and new distribution:      0.009925011719494602\n",
      "Surrogate loss:                           -514241.82541035634\n",
      "\n",
      "********** Iteration 226 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2467\n",
      "Average sum of rewards per episode:       85.5218597487\n",
      "Std of rewards per episode:               129.200340248\n",
      "Entropy:                                  -3528.225362419304\n",
      "KL between old and new distribution:      0.00994666609493041\n",
      "Surrogate loss:                           -539202.3311737943\n",
      "\n",
      "********** Iteration 227 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2498\n",
      "Average sum of rewards per episode:       90.2045468375\n",
      "Std of rewards per episode:               130.177371429\n",
      "Entropy:                                  -2356.243563503696\n",
      "KL between old and new distribution:      0.009840943611755809\n",
      "Surrogate loss:                           -575526.5630812084\n",
      "\n",
      "********** Iteration 228 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2491\n",
      "Average sum of rewards per episode:       95.6618145323\n",
      "Std of rewards per episode:               133.97366158\n",
      "Entropy:                                  -2360.76879264605\n",
      "KL between old and new distribution:      0.009963160584069925\n",
      "Surrogate loss:                           -612792.5006535616\n",
      "\n",
      "********** Iteration 229 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2487\n",
      "Average sum of rewards per episode:       94.1062412545\n",
      "Std of rewards per episode:               133.026246265\n",
      "Entropy:                                  -1774.3287268813474\n",
      "KL between old and new distribution:      0.009962248479123895\n",
      "Surrogate loss:                           -583974.8943941063\n",
      "\n",
      "********** Iteration 230 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2534\n",
      "Average sum of rewards per episode:       94.8332261247\n",
      "Std of rewards per episode:               133.378318761\n",
      "Entropy:                                  -1681.9307906096803\n",
      "KL between old and new distribution:      0.00982849085575403\n",
      "Surrogate loss:                           -596046.7036954979\n",
      "\n",
      "********** Iteration 231 ************\n",
      "Rollout\n",
      "Made rollout\n",
      "Total number of episodes:                 2508\n",
      "Average sum of rewards per episode:       97.0507025518\n",
      "Std of rewards per episode:               136.769564224\n",
      "Entropy:                                  -1347.0166894949857\n",
      "KL between old and new distribution:      0.009856369914877273\n",
      "Surrogate loss:                           -622956.7937116831\n",
      "\n",
      "********** Iteration 232 ************\n",
      "Rollout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made rollout\n",
      "Total number of episodes:                 2573\n",
      "Average sum of rewards per episode:       98.4296572095\n",
      "Std of rewards per episode:               134.652800809\n",
      "Entropy:                                  -1127.6429704293791\n",
      "KL between old and new distribution:      0.00993119318591915\n",
      "Surrogate loss:                           -635043.7726918076\n",
      "\n",
      "********** Iteration 233 ************\n",
      "Rollout\n",
      "Made rollout\n"
     ]
    }
   ],
   "source": [
    "rewards, i = agent.learn(reward=100, max_pathlength=5, n_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent.net.Savemodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ) 0.007 (0.069819509806770153, -0.017916590873314819, -0.062569357573549922, 0.025275189692051322, 0.48370953749318285, 0.32382429822878689, 0.14117034484180541, -0.17979102532712815) [ 0.48370954  0.3238243   0.14117034 -0.17979103]\n",
      "2 ) 100.02 (0.045582557624537938, -0.0040314712451071655, -0.044320371136516434, -0.0098600964252707132, 0.51357823720325491, 0.53002662320452265, 0.25890983035298876, -0.17979102532712815) [ 0.0298687   0.20620232  0.11773949 -0.13491525]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "env.state = np.zeros(4)\n",
    "agent.play(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env1 = gym.make(\"crumb-pick-v0\")\n",
    "#agent.grasp(env1)\n",
    "#agent.pick(env1)\n",
    "#agent.putdown(env1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4392827844092338,\n",
       " 0.2695451879616264,\n",
       " -0.34615669,\n",
       " 0.022142770678141632,\n",
       " 0.2695451879616264,\n",
       " -0.34615669,\n",
       " 0.022142770678141632,\n",
       " 0.2695451879616264,\n",
       " -0.34615669,\n",
       " 0.022142770678141632,\n",
       " -1.5707963267948966,\n",
       " 1.5707963267948966,\n",
       " 0.3795212282445104,\n",
       " -1.5707963267948966)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.4392827844092338, 0.2695451879616264, -0.34615669, 0.022142770678141632, 0.2695451879616264, -0.34615669, 0.022142770678141632, 0.2695451879616264, -0.34615669, 0.022142770678141632, -1.5707963267948966, 1.5707963267948966, 0.3795212282445104, -1.5707963267948966)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ) 0.007000000000000006 (0.23, 0.2, 0.05, 0.07, 0.12, 0.78, 0.32, 0.39) [0.12797938 0.75730049 0.33070355 0.41555789]\n",
      "2 ) 0.017999999999999988 (0.14, 0.11, 0.02, -0.03, 0.36, 1.2, 0.47000000000000003, 0.63) [0.23687681 0.40317045 0.1144163  0.20252017]\n",
      "3 ) 0.011999999999999983 (0.15, 0.12, 0.0, -0.03, 0.35000000000000003, 1.34, 0.53, 0.88) [-0.01286168  0.17568968 -0.00823797  0.0606187 ]\n",
      "4 ) 0.008000000000000007 (0.17, 0.14, -0.05, -0.03, 0.37, 1.46, 0.64, 1.04) [ 0.02067291  0.19924721 -0.09267958 -0.03955087]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b358e1c95a18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrasp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ISA/ros-rl/TRPOagent/agent/agent_TRPO.py\u001b[0m in \u001b[0;36mgrasp\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynthetic_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gym-crumb/Gym-crumb/gym_crumb/envs/crumb_pick_env.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mgripper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gripper_1_link'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mgripper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgripper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gripper_2_link'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ros/kinetic/lib/python2.7/dist-packages/rospy/timer.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(duration)\u001b[0m\n\u001b[1;32m    157\u001b[0m                   \u001b[0;32mnot\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_shutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrostime_cond\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mrostime_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrostime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rostime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0minitial_rostime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.grasp(env1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env1.arm[3].publish(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05530484, -0.29997266,  0.11164202])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def metric(a1, a2):\n",
    "    return ((a1-a2)**2).sum()**(1/2)\n",
    "\n",
    "def get_pose(joint):\n",
    "    a = env1.link_state(joint, '').link_state.pose.position\n",
    "    return np.array([a.x, a.y, a.z])\n",
    "\n",
    "def length():\n",
    "    length = np.zeros(4)\n",
    "    joint = np.zeros((4,3))\n",
    "    joint[0] = get_pose('biceps_link')\n",
    "    joint[1] = get_pose('forearm_link')\n",
    "    joint[2] = get_pose('wrist_1_link')\n",
    "    joint[3] = get_pose('gripper_1_link')/2 + get_pose('gripper_2_link')/2\n",
    "    for i in range(3):\n",
    "        length[i] = metric(joint[i+1], joint[i])\n",
    "    return length\n",
    "\n",
    "box, _ = env1.get_state()\n",
    "box = np.array([box.x, box.y, box.z])\n",
    "bic = get_pose('biceps_link')\n",
    "bic - box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aim1 = np.array([env1.aim.x, env1.aim.y, env1.aim.z])\n",
    "joint = np.zeros((4, 3))\n",
    "joint[0] = get_pose('biceps_link')\n",
    "joint[1] = get_pose('forearm_link')\n",
    "joint[2] = get_pose('wrist_1_link')\n",
    "joint[3] = get_pose('gripper_1_link')/2 + get_pose('gripper_2_link')/2\n",
    "\n",
    "# vectors\n",
    "vec1 = np.zeros((3, 3))\n",
    "vec2 = np.zeros((3, 3))\n",
    "\n",
    "for i in range(3):\n",
    "    vec1[i] = joint[3] - joint[i]\n",
    "    vec2[i] = aim1 - joint[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15000095, 0.14202985, 0.11453303, 0.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04790541,  0.43824102, -0.11164279],\n",
       "       [ 0.04456551,  0.3906848 , -0.25386632],\n",
       "       [ 0.03490639,  0.24898522, -0.25339561]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03635168, -0.13413006,  0.25199619],\n",
       "       [-0.03635168, -0.13413006,  0.25199619],\n",
       "       [-0.03635168, -0.13413006,  0.25199619]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1 - vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
